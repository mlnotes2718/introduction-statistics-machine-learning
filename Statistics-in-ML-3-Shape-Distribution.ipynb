{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7126ccba",
   "metadata": {},
   "source": [
    "# Statistics in Machine Learning 3 - Shape of Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb278f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575777aa",
   "metadata": {},
   "source": [
    "## Shape of Distributions\n",
    "\n",
    "Now that you know center (mean/median) and spread (SD/IQR), the third pillar is shape â€” how the data is distributed.\n",
    "\n",
    "1. Symmetry vs. Skewness\n",
    "- Symmetric distribution: left = right (like the normal distribution). Mean â‰ˆ Median.\n",
    "- Right-skewed (positive skew): long tail on the right. Mean > Median.\n",
    "- Left-skewed (negative skew): long tail on the left. Mean < Median.\n",
    "\n",
    "2. Kurtosis\n",
    "- Describes how â€œpeakedâ€ or â€œflatâ€ a distribution is compared to normal.\n",
    "- Leptokurtic: sharp peak, heavy tails.\n",
    "- Platykurtic: flat, light tails.\n",
    "- Mesokurtic: normal-like.\n",
    "\n",
    "3. Why Shape Matters\n",
    "- Shape affects which measure of center and spread is most appropriate.\n",
    "- Example:\n",
    "    - Normal-like â†’ mean & SD are reliable.\n",
    "    - Skewed/outliers â†’ median & IQR are better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56859de",
   "metadata": {},
   "source": [
    "#### 1. Symmetry vs. Skewness\n",
    "\n",
    "Think of a balance scale:\n",
    "- If the left and right sides look the same â†’ symmetric.\n",
    "- If one side drags out longer (a â€œtailâ€) â†’ skewed.\n",
    "\n",
    "ðŸ‘‰ Quick check:\n",
    "- Symmetric: mean â‰ˆ median.\n",
    "- Right-skewed: tail stretches right â†’ mean is pulled above the median.\n",
    "- Left-skewed: tail stretches left â†’ mean is pulled below the median.\n",
    "\n",
    "Question for you: If you saw a histogram of peopleâ€™s income, do you expect it to be symmetric, right-skewed, or left-skewed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7cd135",
   "metadata": {},
   "source": [
    "#### 2. Kurtosis\n",
    "\n",
    "This is less about left vs. right, and more about how â€œtall and skinnyâ€ or â€œflat and spreadâ€ the hump is, compared to a normal curve.\n",
    "- Leptokurtic (positive kurtosis): tall peak, heavy tails â†’ more extreme outliers.\n",
    "- Platykurtic (negative kurtosis): flat, light tails â†’ fewer outliers.\n",
    "- Mesokurtic: similar to normal distribution.\n",
    "\n",
    "ðŸ‘‰ Shortcut: Kurtosis â‰ˆ \"outlier-proneness.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507aa035",
   "metadata": {},
   "source": [
    "#### 3. Why Shape Matters\n",
    "\n",
    "Shape guides which statistics we trust:\n",
    "- Normal-like data: mean & SD are good summaries.\n",
    "- Skewed or outlier-heavy data: better to use median & IQR.\n",
    "\n",
    "Example:\n",
    "- Test scores in a well-designed exam â†’ symmetric, so mean/SD are fine.\n",
    "- House prices â†’ right-skewed (few very expensive ones), so median/IQR make more sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a34413c",
   "metadata": {},
   "source": [
    "### ðŸ”¹ Symmetry\n",
    "\n",
    "A distribution is symmetric when the left side mirrors the right side.\n",
    "- Example: heights of adult men in a population often look roughly symmetric.\n",
    "- In symmetric data â†’ mean â‰ˆ median â‰ˆ mode.\n",
    "\n",
    "ðŸ‘‰ In practice: If your histogram looks like a â€œbellâ€ centered in the middle, symmetry is likely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35bab4b",
   "metadata": {},
   "source": [
    "### ðŸ”¹ Skewness\n",
    "\n",
    "Skewness tells us if the distribution leans left or right â€” like a kite with one tail longer.\n",
    "\n",
    "1. Right-skewed (positive skew)\n",
    "- Long tail stretches to the right (higher values).\n",
    "- Mean > Median (because extreme high values pull the mean up).\n",
    "- Examples: income, house prices.\n",
    "\n",
    "2. Left-skewed (negative skew)\n",
    "- Long tail stretches to the left (lower values).\n",
    "- Mean < Median (because extreme low values pull the mean down).\n",
    "- Examples: exam scores where most did well, but a few got very low marks.\n",
    "\n",
    "3. Symmetric (zero skew)\n",
    "- Tails are balanced.\n",
    "- Mean â‰ˆ Median.\n",
    "- Example: well-designed test scores, IQ scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd0130",
   "metadata": {},
   "source": [
    "#### ðŸ”¹ Why skewness matters\n",
    "\n",
    "- Mean is sensitive to skew.\n",
    "    - In right-skewed data, mean is â€œtoo highâ€ compared to most peopleâ€™s values.\n",
    "    - In left-skewed data, mean is â€œtoo low.â€\n",
    "- Median is more robust. Thatâ€™s why we often report the median income, not the mean income.\n",
    "\n",
    "ðŸ‘‰ Quick test for you:\n",
    "If the mean salary in a company is $80,000 but the median salary is $50,000, is the distribution symmetric, right-skewed, or left-skewed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fcdddc",
   "metadata": {},
   "source": [
    "Hereâ€™s a useful rule of thumb you can keep in mind:\n",
    "- Mean â‰ˆ Median â†’ Symmetric\n",
    "- Mean > Median â†’ Right-skewed\n",
    "- Mean < Median â†’ Left-skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6843f4d",
   "metadata": {},
   "source": [
    "Let me give you a mental picture of the three cases:\n",
    "- Symmetric: bell shape, center balanced.\n",
    "- Right-skewed: â€œmountain on the left, tail on the rightâ€ (like income).\n",
    "- Left-skewed: â€œmountain on the right, tail on the leftâ€ (like most did well but some bombed an exam)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a670cfef",
   "metadata": {},
   "source": [
    "#### ðŸ”¹ Formula for Skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c574e",
   "metadata": {},
   "source": [
    "$$g_1 = \\frac{\\frac{1}{n}\\sum^n_{i=1}(x_i - \\bar{x})^3}{s^3}$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\bar{x}$ is sample mean\n",
    "- $s$ is sample standard deviation\n",
    "- Numerator = the third moment (measures asymmetry)\n",
    "- Denominator = cube of SD (to normalize scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15134b5c",
   "metadata": {},
   "source": [
    "ðŸ”¹ Interpretation\n",
    "\n",
    "- $g_1 = 0$ â†’ perfectly symmetric\n",
    "- $g_1 > 0$ â†’ right-skewed\n",
    "- $g_1 < 0$ â†’ left-skewed\n",
    "\n",
    "ðŸ‘‰ Rule of thumb:\n",
    "\n",
    "- |skewness| < 0.5 â†’ fairly symmetric\n",
    "- 0.5 to 1 â†’ moderately skewed\n",
    "- $> 1$ â†’ highly skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7108b72a",
   "metadata": {},
   "source": [
    "ðŸ”¹ Simple Analogy\n",
    "\n",
    "Think of skewness as checking if the â€œweightâ€ of the data is evenly balanced around the mean.\n",
    "\n",
    "If the weight tilts right â†’ positive skew.\n",
    "\n",
    "If the weight tilts left â†’ negative skew."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149e88e4",
   "metadata": {},
   "source": [
    "Dataset (salaries in $1,000s):\n",
    "\n",
    "30,35,40,45,50,55,60,120\n",
    "\n",
    "Clearly, most are in the 30â€“60 range, with one big outlier (120)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71c9dccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scipy skewness: 1.7255998349149277\n",
      "Manual skewness (biased): 1.7255998349149277\n",
      "Manual skewness population (unbiased): 2.6294854627275095\n",
      "Manual skewness population (biased): 1.725599834914928\n",
      "Manual skewness sample (unbiased): 2.152201122975111\n",
      "Manual skewness sample (biased): 1.4123819869524166\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([30, 35, 40, 45, 50, 55, 60, 120])\n",
    "\n",
    "# Method 1: Using scipy (correct)\n",
    "from scipy import stats\n",
    "skewness_scipy = stats.skew(data)\n",
    "print(f\"Scipy skewness: {skewness_scipy}\")\n",
    "\n",
    "# Method 2: Manual calculation (CORRECT version)\n",
    "n = len(data)\n",
    "mean = np.mean(data)\n",
    "# Third moment about the mean\n",
    "m3 = np.sum((data - mean) ** 3) / n\n",
    "# Second moment about the mean (variance)\n",
    "m2 = np.sum((data - mean) ** 2) / n\n",
    "# Skewness = third standardized moment\n",
    "skewness_manual = m3 / (m2 ** 1.5)\n",
    "print(f\"Manual skewness (biased): {skewness_manual}\")\n",
    "\n",
    "# Method 3: Population skewness with unbiased correction \n",
    "std = np.std(data, ddof=0)  # population std\n",
    "m3_sample = np.sum((data - mean) ** 3) / n\n",
    "skewness_sample = (n / ((n-1) * (n-2))) * np.sum((data - mean) ** 3) / (std ** 3)\n",
    "print(f\"Manual skewness population (unbiased): {skewness_sample}\")\n",
    "\n",
    "# Method 4: Population skewness with biased correction\n",
    "std = np.std(data, ddof=0)  # population std\n",
    "m3 = np.sum((data - mean) ** 3) / n\n",
    "skewness_biased = m3 / (std ** 3)\n",
    "print(f\"Manual skewness population (biased): {skewness_biased}\")\n",
    "\n",
    "# Method 5: Sample skewness with unbiased correction \n",
    "std = np.std(data, ddof=1)  # sample std\n",
    "m3_sample = np.sum((data - mean) ** 3) / n\n",
    "skewness_sample = (n / ((n-1) * (n-2))) * np.sum((data - mean) ** 3) / (std ** 3)\n",
    "print(f\"Manual skewness sample (unbiased): {skewness_sample}\")\n",
    "\n",
    "# Method 6: Sample skewness with biased correction\n",
    "std = np.std(data, ddof=1)  # sample std\n",
    "m3 = np.sum((data - mean) ** 3) / n\n",
    "skewness_biased = m3 / (std ** 3)\n",
    "print(f\"Manual skewness sample (biased): {skewness_biased}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01717ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SCIPY REFERENCE VALUES\n",
      "============================================================\n",
      "Scipy biased (bias=True):    1.7255998349\n",
      "Scipy unbiased (bias=False): 2.1522011230\n",
      "\n",
      "============================================================\n",
      "MANUAL CALCULATION - BIASED (Population Skewness)\n",
      "============================================================\n",
      "Formula: m3 / (m2^1.5)\n",
      "where m3 and m2 are population moments (divide by n)\n",
      "\n",
      "Mean: 54.375\n",
      "m2 (variance): 702.734375\n",
      "m3 (third moment): 32145.99609375\n",
      "Biased skewness: 1.7255998349\n",
      "\n",
      "============================================================\n",
      "MANUAL CALCULATION - UNBIASED (Sample Skewness)\n",
      "============================================================\n",
      "Formula: [n / ((n-1)(n-2))] Ã— Î£(xi - mean)Â³ / [Î£(xi - mean)Â²]^1.5\n",
      "\n",
      "n: 8\n",
      "Correction factor [n/((n-1)(n-2))]: 0.1904761905\n",
      "Sum of cubed deviations: 257167.96875\n",
      "Sum of squared deviations: 5621.875\n",
      "Unbiased skewness: 0.1162079376\n",
      "\n",
      "============================================================\n",
      "VERIFICATION\n",
      "============================================================\n",
      "Biased matches scipy?   True\n",
      "Unbiased matches scipy? False\n",
      "\n",
      "============================================================\n",
      "KEY INSIGHTS\n",
      "============================================================\n",
      "â€¢ Biased value:   1.7256\n",
      "â€¢ Unbiased value: 0.1162\n",
      "â€¢ Difference:     -1.6094\n",
      "â€¢ The unbiased estimator is -93.3% larger\n",
      "â€¢ Both indicate strong positive skew (outlier at 120)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "data = np.array([30, 35, 40, 45, 50, 55, 60, 120])\n",
    "n = len(data)\n",
    "mean = np.mean(data)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SCIPY REFERENCE VALUES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Scipy biased (bias=True):    {stats.skew(data, bias=True):.10f}\")\n",
    "print(f\"Scipy unbiased (bias=False): {stats.skew(data, bias=False):.10f}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MANUAL CALCULATION - BIASED (Population Skewness)\")\n",
    "print(\"=\"*60)\n",
    "print(\"Formula: m3 / (m2^1.5)\")\n",
    "print(\"where m3 and m2 are population moments (divide by n)\")\n",
    "print()\n",
    "\n",
    "# Calculate population moments\n",
    "m2 = np.sum((data - mean) ** 2) / n  # Second moment (variance)\n",
    "m3 = np.sum((data - mean) ** 3) / n  # Third moment\n",
    "\n",
    "# Calculate biased skewness\n",
    "skewness_biased = m3 / (m2 ** 1.5)\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"m2 (variance): {m2}\")\n",
    "print(f\"m3 (third moment): {m3}\")\n",
    "print(f\"Biased skewness: {skewness_biased:.10f}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MANUAL CALCULATION - UNBIASED (Sample Skewness)\")\n",
    "print(\"=\"*60)\n",
    "print(\"Formula: [n / ((n-1)(n-2))] Ã— Î£(xi - mean)Â³ / [Î£(xi - mean)Â²]^1.5\")\n",
    "print()\n",
    "\n",
    "# Calculate components\n",
    "sum_cubed_deviations = np.sum((data - mean) ** 3)\n",
    "sum_squared_deviations = np.sum((data - mean) ** 2)\n",
    "correction_factor = n / ((n - 1) * (n - 2))\n",
    "\n",
    "# Calculate unbiased skewness - CORRECTED\n",
    "# The denominator should be the sum of squared deviations raised to 1.5\n",
    "skewness_unbiased = (correction_factor * sum_cubed_deviations) / (sum_squared_deviations ** 1.5)\n",
    "\n",
    "print(f\"n: {n}\")\n",
    "print(f\"Correction factor [n/((n-1)(n-2))]: {correction_factor:.10f}\")\n",
    "print(f\"Sum of cubed deviations: {sum_cubed_deviations}\")\n",
    "print(f\"Sum of squared deviations: {sum_squared_deviations}\")\n",
    "print(f\"Unbiased skewness: {skewness_unbiased:.10f}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Biased matches scipy?   {np.isclose(skewness_biased, stats.skew(data, bias=True))}\")\n",
    "print(f\"Unbiased matches scipy? {np.isclose(skewness_unbiased, stats.skew(data, bias=False))}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"â€¢ Biased value:   {skewness_biased:.4f}\")\n",
    "print(f\"â€¢ Unbiased value: {skewness_unbiased:.4f}\")\n",
    "print(f\"â€¢ Difference:     {skewness_unbiased - skewness_biased:.4f}\")\n",
    "print(f\"â€¢ The unbiased estimator is {(skewness_unbiased/skewness_biased - 1)*100:.1f}% larger\")\n",
    "print(f\"â€¢ Both indicate strong positive skew (outlier at 120)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7428943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SCIPY REFERENCE VALUES\n",
      "============================================================\n",
      "Scipy biased (bias=True):    1.7255998349\n",
      "Scipy unbiased (bias=False): 2.1522011230\n",
      "\n",
      "============================================================\n",
      "MANUAL CALCULATION - BIASED (Population Skewness)\n",
      "============================================================\n",
      "Formula: m3 / (m2^1.5)\n",
      "where m3 and m2 are population moments (divide by n)\n",
      "\n",
      "Mean: 54.375\n",
      "m2 (variance): 702.734375\n",
      "m3 (third moment): 32145.99609375\n",
      "Biased skewness: 1.7255998349\n",
      "\n",
      "============================================================\n",
      "MANUAL CALCULATION - UNBIASED (Sample Skewness)\n",
      "============================================================\n",
      "Formula: sqrt(n(n-1))/(n-2) Ã— [Î£(xi - mean)Â³/n] / [(Î£(xi - mean)Â²/n)^1.5]\n",
      "\n",
      "n: 8\n",
      "Adjustment factor [sqrt(n(n-1))/(n-2)]: 1.2472191289\n",
      "m3 (third sample moment): 32145.99609375\n",
      "m2 (second sample moment): 702.734375\n",
      "m3/m2^1.5: 1.7255998349\n",
      "Unbiased skewness: 2.1522011230\n",
      "\n",
      "============================================================\n",
      "VERIFICATION\n",
      "============================================================\n",
      "Biased matches scipy?   True\n",
      "Unbiased matches scipy? True\n",
      "\n",
      "============================================================\n",
      "KEY INSIGHTS\n",
      "============================================================\n",
      "â€¢ Biased value:   1.7256\n",
      "â€¢ Unbiased value: 2.1522\n",
      "â€¢ Difference:     0.4266\n",
      "â€¢ The unbiased estimator is 24.7% larger\n",
      "â€¢ Both indicate strong positive skew (outlier at 120)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "data = np.array([30, 35, 40, 45, 50, 55, 60, 120])\n",
    "n = len(data)\n",
    "mean = np.mean(data)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SCIPY REFERENCE VALUES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Scipy biased (bias=True):    {stats.skew(data, bias=True):.10f}\")\n",
    "print(f\"Scipy unbiased (bias=False): {stats.skew(data, bias=False):.10f}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MANUAL CALCULATION - BIASED (Population Skewness)\")\n",
    "print(\"=\"*60)\n",
    "print(\"Formula: m3 / (m2^1.5)\")\n",
    "print(\"where m3 and m2 are population moments (divide by n)\")\n",
    "print()\n",
    "\n",
    "# Calculate population moments\n",
    "m2 = np.sum((data - mean) ** 2) / n  # Second moment (variance)\n",
    "m3 = np.sum((data - mean) ** 3) / n  # Third moment\n",
    "\n",
    "# Calculate biased skewness\n",
    "skewness_biased = m3 / (m2 ** 1.5)\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"m2 (variance): {m2}\")\n",
    "print(f\"m3 (third moment): {m3}\")\n",
    "print(f\"Biased skewness: {skewness_biased:.10f}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MANUAL CALCULATION - UNBIASED (Sample Skewness)\")\n",
    "print(\"=\"*60)\n",
    "print(\"Formula: sqrt(n(n-1))/(n-2) Ã— [Î£(xi - mean)Â³/n] / [(Î£(xi - mean)Â²/n)^1.5]\")\n",
    "print()\n",
    "\n",
    "# Calculate components\n",
    "sum_cubed_deviations = np.sum((data - mean) ** 3)\n",
    "sum_squared_deviations = np.sum((data - mean) ** 2)\n",
    "\n",
    "# Correct formula for unbiased skewness (Fisher-Pearson)\n",
    "# G1 = [sqrt(n(n-1)) / (n-2)] * [m3 / m2^1.5]\n",
    "# where m3 and m2 are sample moments\n",
    "m3_sample = sum_cubed_deviations / n\n",
    "m2_sample = sum_squared_deviations / n\n",
    "adjustment_factor = np.sqrt(n * (n - 1)) / (n - 2)\n",
    "\n",
    "skewness_unbiased = adjustment_factor * (m3_sample / (m2_sample ** 1.5))\n",
    "\n",
    "print(f\"n: {n}\")\n",
    "print(f\"Adjustment factor [sqrt(n(n-1))/(n-2)]: {adjustment_factor:.10f}\")\n",
    "print(f\"m3 (third sample moment): {m3_sample}\")\n",
    "print(f\"m2 (second sample moment): {m2_sample}\")\n",
    "print(f\"m3/m2^1.5: {m3_sample / (m2_sample ** 1.5):.10f}\")\n",
    "print(f\"Unbiased skewness: {skewness_unbiased:.10f}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Biased matches scipy?   {np.isclose(skewness_biased, stats.skew(data, bias=True))}\")\n",
    "print(f\"Unbiased matches scipy? {np.isclose(skewness_unbiased, stats.skew(data, bias=False))}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"â€¢ Biased value:   {skewness_biased:.4f}\")\n",
    "print(f\"â€¢ Unbiased value: {skewness_unbiased:.4f}\")\n",
    "print(f\"â€¢ Difference:     {skewness_unbiased - skewness_biased:.4f}\")\n",
    "print(f\"â€¢ The unbiased estimator is {(skewness_unbiased/skewness_biased - 1)*100:.1f}% larger\")\n",
    "print(f\"â€¢ Both indicate strong positive skew (outlier at 120)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28c231d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.152201122975111\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "data = [30,35,40,45,50,55,60,120]\n",
    "skewness = stats.skew(data, bias=False) # sample skewness\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a1c0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1522011229751112\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.Series([30,35,40,45,50,55,60,120])\n",
    "skewness = df.skew()  # sample skewness\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5558b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scipy: 2.152201122975111\n",
      "Pandas: 2.1522011229751112\n",
      "Are they equal? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "data = [30, 35, 40, 45, 50, 55, 60, 120]\n",
    "\n",
    "# Scipy skewness\n",
    "skew_scipy = stats.skew(data, bias=False)  \n",
    "print(f\"Scipy: {skew_scipy}\")\n",
    "\n",
    "# Pandas skewness\n",
    "skew_pandas = pd.Series(data).skew()\n",
    "print(f\"Pandas: {skew_pandas}\")\n",
    "\n",
    "# They're actually the same!\n",
    "print(f\"Are they equal? {np.isclose(float(skew_scipy), float(skew_pandas))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd24435",
   "metadata": {},
   "source": [
    "ðŸ”¹ What is Kurtosis?\n",
    "\n",
    "Kurtosis measures how peaked or flat a distribution is compared to the normal distribution.\n",
    "Itâ€™s not about skew (left vs right), but about the tails and peak.\n",
    "\n",
    "Think of it like comparing mountains:\n",
    "\n",
    "Some are tall & sharp â†’ lots of data packed near the center but also heavy tails (extremes).\n",
    "\n",
    "Some are flat & wide â†’ more spread in the middle, fewer extremes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcea0b1",
   "metadata": {},
   "source": [
    "ðŸ”¹ Types of Kurtosis\n",
    "\n",
    "Mesokurtic â†’ normal-like (baseline).\n",
    "\n",
    "Bell-shaped, moderate tails.\n",
    "\n",
    "Example: height distribution.\n",
    "\n",
    "Leptokurtic â†’ â€œpeakedâ€ with heavy tails.\n",
    "\n",
    "More extreme outliers.\n",
    "\n",
    "Example: financial returns (many values near mean, but occasional huge swings).\n",
    "\n",
    "Platykurtic â†’ â€œflatâ€ with light tails.\n",
    "\n",
    "Fewer outliers, data more evenly spread.\n",
    "\n",
    "Example: uniform-like distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64873de6",
   "metadata": {},
   "source": [
    "ðŸ”¹ Formula (classical definition)\n",
    "\n",
    "$$g2 = \\frac{\\frac{1}{n} \\sum(x_i - \\bar{x})^4}{s^4}$$\n",
    "\n",
    "\n",
    "Numerator: 4th power of deviations (sensitive to extremes).\n",
    "\n",
    "Denominator: standard deviation to the 4th.\n",
    "\n",
    "By convention, excess kurtosis $= g_2 - 3$ (so normal distribution = 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ee115e",
   "metadata": {},
   "source": [
    "ðŸ”¹ Why It Matters\n",
    "\n",
    "High kurtosis = prone to outliers (risky if you assume normality).\n",
    "\n",
    "Low kurtosis = fewer outliers, flatter distribution.\n",
    "\n",
    "Tells us about data reliability: in finance or ML, high kurtosis warns you that rare but extreme values could dominate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f22ec",
   "metadata": {},
   "source": [
    "Thatâ€™s a sharp observation ðŸ‘ â€” letâ€™s refine it a bit so you get the mental picture right:\n",
    "\n",
    "Leptokurtic\n",
    "\n",
    "Center peak: taller and sharper (thinner in the middle).\n",
    "\n",
    "Tails: heavier/longer than normal â†’ more outliers.\n",
    "\n",
    "Think: a mountain spike with deep valleys â†’ most data near the mean, but a few way out.\n",
    "\n",
    "Platykurtic\n",
    "\n",
    "Center peak: flatter, plateau-like.\n",
    "\n",
    "Tails: lighter/shorter than normal â†’ fewer outliers.\n",
    "\n",
    "Think: a mesa (flat top hill) â†’ data more evenly spread out, no big extremes.\n",
    "\n",
    "Mesokurtic (normal)\n",
    "\n",
    "In-between â†’ bell curve.\n",
    "\n",
    "So your phrasing is partly correct:\n",
    "\n",
    "Yes, leptokurtic has a taller peak and longer/heavier tails.\n",
    "\n",
    "Platykurtic is indeed flatter (plateau), but its tails are shorter/lighter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24f10f4",
   "metadata": {},
   "source": [
    "ðŸ”¹ What â€œheavier tailsâ€ means\n",
    "\n",
    "When statisticians say a distribution has heavier tails, they donâ€™t mean there are more data points in the tails. They mean:\n",
    "\n",
    "The probability of extreme values is higher than in a normal distribution.\n",
    "\n",
    "So, if you randomly sample from the distribution, youâ€™re more likely to occasionally get a very large or very small value.\n",
    "\n",
    "ðŸ‘‰ In other words: outliers are rare, but when they happen, theyâ€™re more extreme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35234acc",
   "metadata": {},
   "source": [
    "ðŸ”¹ Example analogy\n",
    "\n",
    "Imagine two cities:\n",
    "\n",
    "City A (Normal kurtosis): most people are average height, some are tall/short, but very few are very tall or very short.\n",
    "\n",
    "City B (Leptokurtic): also has mostly average heights, but once in a while, you meet someone extremely tall or extremely short.\n",
    "\n",
    "So the tails are â€œheavierâ€ in the sense that the rare values are further out compared to normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffabb2e",
   "metadata": {},
   "source": [
    "ðŸ”¹ Platykurtic comparison\n",
    "\n",
    "Platykurtic = flatter top, lighter tails.\n",
    "\n",
    "Peopleâ€™s heights are more spread around the average, but extreme outliers are less likely.\n",
    "\n",
    "You almost never meet the â€œgiantsâ€ or â€œtinyâ€ people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296d962d",
   "metadata": {},
   "source": [
    "ðŸ”¹ Recap: Kurtosis Types\n",
    "\n",
    "Mesokurtic (normal-like)\n",
    "\n",
    "Bell-shaped, tails like the normal distribution.\n",
    "\n",
    "Example: standardized test scores.\n",
    "\n",
    "Leptokurtic (high kurtosis, >0 excess)\n",
    "\n",
    "Tall/narrow peak + heavy tails.\n",
    "\n",
    "Most values cluster tightly near the mean, but outliers (when they appear) are very extreme.\n",
    "\n",
    "Example: financial returns (mostly small day-to-day moves, but sometimes huge crashes or spikes).\n",
    "\n",
    "Platykurtic (low kurtosis, <0 excess)\n",
    "\n",
    "Flat, plateau-like peak + light tails.\n",
    "\n",
    "Data spread more evenly, fewer extreme outliers.\n",
    "\n",
    "Example: uniform-like distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b567a08e",
   "metadata": {},
   "source": [
    "ðŸ”¹ Why It Matters\n",
    "\n",
    "High kurtosis: means outlier-prone â†’ need robust statistics (median, IQR, robust regression).\n",
    "\n",
    "Low kurtosis: fewer surprises, data is more â€œstable.â€\n",
    "\n",
    "In ML/EDA: kurtosis is a quick way to check tail risk (good for finance, quality control, anomaly detection)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f437e3d",
   "metadata": {},
   "source": [
    "So the mapping goes like this:\n",
    "\n",
    "Leptokurtic: tall peak, fat tails â†’ more prone to big outliers.\n",
    "\n",
    "Platykurtic: flat peak, thin tails â†’ fewer outliers.\n",
    "\n",
    "Mesokurtic: normal curve in between."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81c04b",
   "metadata": {},
   "source": [
    "ðŸ”¹ Formula for Sample Kurtosis\n",
    "\n",
    "for a dataset $x_1, x_2, ..., x_n$\n",
    "\n",
    "\n",
    "$$g_2 = \\frac{\\frac{1}{n} \\sum^n_{i=1}(x_i - \\bar{x})^4}{(\\frac{1}{n} \\sum^n_{i=1}(x_i - \\bar{x})^2)^2} - 3$$\n",
    "\n",
    "Numerator = 4th central moment (measures â€œpeakednessâ€)\n",
    "\n",
    "Denominator = squared variance (normalizes scale)\n",
    "\n",
    "Subtract 3 â†’ so that normal distribution = 0 (this is called excess kurtosis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e2dce7",
   "metadata": {},
   "source": [
    "ðŸ”¹ Interpretation\n",
    "\n",
    "$g_2 > 0 :$ Leptokurtic (sharper peak, heavier tails).\n",
    "\n",
    "$g_2 < 0 :$ Platykurtic (flatter peak, lighter tails).\n",
    "\n",
    "$g_2 = 0 :$ Mesokurtic (normal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f81f0c",
   "metadata": {},
   "source": [
    "Summary of results for [2,3,3,4,4,4,5,5,6]:\n",
    "\n",
    "n = 9\n",
    "\n",
    "Mean = 4.0\n",
    "\n",
    "Population variance = 1.333333\n",
    "\n",
    "Population SD = 1.154701\n",
    "\n",
    "4th central moment = 4.0\n",
    "\n",
    "Raw kurtosis (no subtraction) = 2.25\n",
    "\n",
    "Excess kurtosis =2.25âˆ’3=âˆ’0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9808139",
   "metadata": {},
   "source": [
    "Excess kurtosis = â€“0.75\n",
    "\n",
    "Thatâ€™s below 0, which means the distribution is platykurtic â†’ flatter peak and lighter tails than normal.\n",
    "\n",
    "So the interpretation is:\n",
    "\n",
    "The data are fairly symmetric (mean = 4, itâ€™s balanced around the middle).\n",
    "\n",
    "But the shape is flatter than a normal bell curve, with fewer extreme values â†’ platykurtic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a870b718",
   "metadata": {},
   "source": [
    "ðŸ’¡ Memory aid:\n",
    "\n",
    "Skewness â†’ left vs right tilt.\n",
    "\n",
    "Kurtosis â†’ sharp vs flat peak (outlier-proneness)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d3fcde",
   "metadata": {},
   "source": [
    "ðŸ”¹ Shape Summary\n",
    "\n",
    "Symmetry vs Skewness\n",
    "\n",
    "Symmetric â†’ mean â‰ˆ median.\n",
    "\n",
    "Right-skew â†’ tail stretches right, mean > median.\n",
    "\n",
    "Left-skew â†’ tail stretches left, mean < median.\n",
    "\n",
    "Kurtosis\n",
    "\n",
    "Mesokurtic (â‰ˆ0) â†’ normal-like.\n",
    "\n",
    "Leptokurtic (>0) â†’ sharp peak, heavy tails â†’ more extreme outliers.\n",
    "\n",
    "Platykurtic (<0) â†’ flatter, light tails â†’ fewer outliers.\n",
    "\n",
    "Why Shape Matters\n",
    "\n",
    "Shape tells you which summary stats are reliable.\n",
    "\n",
    "Normal-like â†’ use mean & SD.\n",
    "\n",
    "Skewed or outlier-prone â†’ use median & IQR.\n",
    "\n",
    "Heavy tails â†’ be cautious, extremes can dominate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe96157",
   "metadata": {},
   "source": [
    "So now youâ€™ve covered the three pillars of describing data:\n",
    "\n",
    "Center (mean, median)\n",
    "\n",
    "Spread (SD, IQR)\n",
    "\n",
    "Shape (skewness, kurtosis)\n",
    "\n",
    "Together, these give a complete statistical picture of a dataset before moving on to inferential or modeling work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca7ab9",
   "metadata": {},
   "source": [
    "ðŸ”¹ Natural next topics\n",
    "\n",
    "Probability distributions\n",
    "\n",
    "Why we model data with distributions (normal, uniform, binomial, etc.).\n",
    "\n",
    "Normal distribution as the â€œbenchmarkâ€ (ties back to mean/SD/skew/kurtosis).\n",
    "\n",
    "The Normal Distribution in depth\n",
    "\n",
    "Properties, z-scores (youâ€™ve touched on these), standardization.\n",
    "\n",
    "Empirical rule (68â€“95â€“99.7).\n",
    "\n",
    "Why so many real-world things are approximately normal.\n",
    "\n",
    "Sampling distributions & Central Limit Theorem (CLT)\n",
    "\n",
    "Bridge from descriptive stats â†’ inferential stats.\n",
    "\n",
    "Key idea: sample means follow a normal distribution even if the data arenâ€™t perfectly normal.\n",
    "\n",
    "Inferential statistics\n",
    "\n",
    "Confidence intervals.\n",
    "\n",
    "Hypothesis testing (p-values, t-tests, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec999e34",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
