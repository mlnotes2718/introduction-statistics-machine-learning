{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7126ccba",
   "metadata": {},
   "source": [
    "# Statistics in Machine Learning 3 - Shape of Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb278f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575777aa",
   "metadata": {},
   "source": [
    "## Shape of Distributions\n",
    "\n",
    "Now that you know center (mean/median) and spread (SD/IQR), the third pillar is shape ‚Äî how the data is distributed.\n",
    "\n",
    "1. Symmetry vs. Skewness\n",
    "- Symmetric distribution: left = right (like the normal distribution). Mean ‚âà Median.\n",
    "- Right-skewed (positive skew): long tail on the right. Mean > Median.\n",
    "- Left-skewed (negative skew): long tail on the left. Mean < Median.\n",
    "\n",
    "2. Kurtosis\n",
    "- Describes how ‚Äúpeaked‚Äù or ‚Äúflat‚Äù a distribution is compared to normal.\n",
    "- Leptokurtic: sharp peak, heavy tails.\n",
    "- Platykurtic: flat, light tails.\n",
    "- Mesokurtic: normal-like.\n",
    "\n",
    "3. Why Shape Matters\n",
    "- Shape affects which measure of center and spread is most appropriate.\n",
    "- Example:\n",
    "    - Normal-like ‚Üí mean & SD are reliable.\n",
    "    - Skewed/outliers ‚Üí median & IQR are better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56859de",
   "metadata": {},
   "source": [
    "#### 1. Symmetry vs. Skewness\n",
    "\n",
    "Think of a balance scale:\n",
    "- If the left and right sides look the same ‚Üí symmetric.\n",
    "- If one side drags out longer (a ‚Äútail‚Äù) ‚Üí skewed.\n",
    "\n",
    "üëâ Quick check:\n",
    "- Symmetric: mean ‚âà median.\n",
    "- Right-skewed: tail stretches right ‚Üí mean is pulled above the median.\n",
    "- Left-skewed: tail stretches left ‚Üí mean is pulled below the median.\n",
    "\n",
    "Question for you: If you saw a histogram of people‚Äôs income, do you expect it to be symmetric, right-skewed, or left-skewed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7cd135",
   "metadata": {},
   "source": [
    "#### 2. Kurtosis\n",
    "\n",
    "This is less about left vs. right, and more about how ‚Äútall and skinny‚Äù or ‚Äúflat and spread‚Äù the hump is, compared to a normal curve.\n",
    "- Leptokurtic (positive kurtosis): tall peak, heavy tails ‚Üí more extreme outliers.\n",
    "- Platykurtic (negative kurtosis): flat, light tails ‚Üí fewer outliers.\n",
    "- Mesokurtic: similar to normal distribution.\n",
    "\n",
    "üëâ Shortcut: Kurtosis ‚âà \"outlier-proneness.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507aa035",
   "metadata": {},
   "source": [
    "#### 3. Why Shape Matters\n",
    "\n",
    "Shape guides which statistics we trust:\n",
    "- Normal-like data: mean & SD are good summaries.\n",
    "- Skewed or outlier-heavy data: better to use median & IQR.\n",
    "\n",
    "Example:\n",
    "- Test scores in a well-designed exam ‚Üí symmetric, so mean/SD are fine.\n",
    "- House prices ‚Üí right-skewed (few very expensive ones), so median/IQR make more sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a34413c",
   "metadata": {},
   "source": [
    "### üîπ Symmetry\n",
    "\n",
    "A distribution is symmetric when the left side mirrors the right side.\n",
    "- Example: heights of adult men in a population often look roughly symmetric.\n",
    "- In symmetric data ‚Üí mean ‚âà median ‚âà mode.\n",
    "\n",
    "üëâ In practice: If your histogram looks like a ‚Äúbell‚Äù centered in the middle, symmetry is likely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35bab4b",
   "metadata": {},
   "source": [
    "### üîπ Skewness\n",
    "\n",
    "Skewness tells us if the distribution leans left or right ‚Äî like a kite with one tail longer.\n",
    "\n",
    "1. Right-skewed (positive skew)\n",
    "- Long tail stretches to the right (higher values).\n",
    "- Mean > Median (because extreme high values pull the mean up).\n",
    "- Examples: income, house prices.\n",
    "\n",
    "2. Left-skewed (negative skew)\n",
    "- Long tail stretches to the left (lower values).\n",
    "- Mean < Median (because extreme low values pull the mean down).\n",
    "- Examples: exam scores where most did well, but a few got very low marks.\n",
    "\n",
    "3. Symmetric (zero skew)\n",
    "- Tails are balanced.\n",
    "- Mean ‚âà Median.\n",
    "- Example: well-designed test scores, IQ scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd0130",
   "metadata": {},
   "source": [
    "#### üîπ Why skewness matters\n",
    "\n",
    "- Mean is sensitive to skew.\n",
    "    - In right-skewed data, mean is ‚Äútoo high‚Äù compared to most people‚Äôs values.\n",
    "    - In left-skewed data, mean is ‚Äútoo low.‚Äù\n",
    "- Median is more robust. That‚Äôs why we often report the median income, not the mean income.\n",
    "\n",
    "üëâ Quick test for you:\n",
    "If the mean salary in a company is $80,000 but the median salary is $50,000, is the distribution symmetric, right-skewed, or left-skewed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fcdddc",
   "metadata": {},
   "source": [
    "Here‚Äôs a useful rule of thumb you can keep in mind:\n",
    "- Mean ‚âà Median ‚Üí Symmetric\n",
    "- Mean > Median ‚Üí Right-skewed\n",
    "- Mean < Median ‚Üí Left-skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6843f4d",
   "metadata": {},
   "source": [
    "Let me give you a mental picture of the three cases:\n",
    "- Symmetric: bell shape, center balanced.\n",
    "- Right-skewed: ‚Äúmountain on the left, tail on the right‚Äù (like income).\n",
    "- Left-skewed: ‚Äúmountain on the right, tail on the left‚Äù (like most did well but some bombed an exam)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a670cfef",
   "metadata": {},
   "source": [
    "#### üîπ Formula for Skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c574e",
   "metadata": {},
   "source": [
    "$$g_1 = \\frac{\\frac{1}{n}\\sum^n_{i=1}(x_i - \\bar{x})^3}{s^3}$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\bar{x}$ is sample mean\n",
    "- $s$ is sample standard deviation\n",
    "- Numerator = the third moment (measures asymmetry)\n",
    "- Denominator = cube of SD (to normalize scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15134b5c",
   "metadata": {},
   "source": [
    "üîπ Interpretation\n",
    "\n",
    "- $g_1 = 0$ ‚Üí perfectly symmetric\n",
    "- $g_1 > 0$ ‚Üí right-skewed\n",
    "- $g_1 < 0$ ‚Üí left-skewed\n",
    "\n",
    "üëâ Rule of thumb:\n",
    "\n",
    "- |skewness| < 0.5 ‚Üí fairly symmetric\n",
    "- 0.5 to 1 ‚Üí moderately skewed\n",
    "- $> 1$ ‚Üí highly skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7108b72a",
   "metadata": {},
   "source": [
    "üîπ Simple Analogy\n",
    "\n",
    "Think of skewness as checking if the ‚Äúweight‚Äù of the data is evenly balanced around the mean.\n",
    "\n",
    "If the weight tilts right ‚Üí positive skew.\n",
    "\n",
    "If the weight tilts left ‚Üí negative skew."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149e88e4",
   "metadata": {},
   "source": [
    "Dataset (salaries in $1,000s):\n",
    "\n",
    "30,35,40,45,50,55,60,120\n",
    "\n",
    "Clearly, most are in the 30‚Äì60 range, with one big outlier (120)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71c9dccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scipy skewness: 1.7255998349149277\n",
      "Manual skewness (biased): 1.7255998349149277\n",
      "Manual skewness population (unbiased): 2.6294854627275095\n",
      "Manual skewness population (biased): 1.725599834914928\n",
      "Manual skewness sample (unbiased): 2.152201122975111\n",
      "Manual skewness sample (biased): 1.4123819869524166\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([30, 35, 40, 45, 50, 55, 60, 120])\n",
    "\n",
    "# Method 1: Using scipy (correct)\n",
    "from scipy import stats\n",
    "skewness_scipy = stats.skew(data)\n",
    "print(f\"Scipy skewness: {skewness_scipy}\")\n",
    "\n",
    "# Method 2: Manual calculation (CORRECT version)\n",
    "n = len(data)\n",
    "mean = np.mean(data)\n",
    "# Third moment about the mean\n",
    "m3 = np.sum((data - mean) ** 3) / n\n",
    "# Second moment about the mean (variance)\n",
    "m2 = np.sum((data - mean) ** 2) / n\n",
    "# Skewness = third standardized moment\n",
    "skewness_manual = m3 / (m2 ** 1.5)\n",
    "print(f\"Manual skewness (biased): {skewness_manual}\")\n",
    "\n",
    "# Method 3: Population skewness with unbiased correction \n",
    "std = np.std(data, ddof=0)  # population std\n",
    "m3_sample = np.sum((data - mean) ** 3) / n\n",
    "skewness_sample = (n / ((n-1) * (n-2))) * np.sum((data - mean) ** 3) / (std ** 3)\n",
    "print(f\"Manual skewness population (unbiased): {skewness_sample}\")\n",
    "\n",
    "# Method 4: Population skewness with biased correction\n",
    "std = np.std(data, ddof=0)  # population std\n",
    "m3 = np.sum((data - mean) ** 3) / n\n",
    "skewness_biased = m3 / (std ** 3)\n",
    "print(f\"Manual skewness population (biased): {skewness_biased}\")\n",
    "\n",
    "# Method 5: Sample skewness with unbiased correction \n",
    "std = np.std(data, ddof=1)  # sample std\n",
    "m3_sample = np.sum((data - mean) ** 3) / n\n",
    "skewness_sample = (n / ((n-1) * (n-2))) * np.sum((data - mean) ** 3) / (std ** 3)\n",
    "print(f\"Manual skewness sample (unbiased): {skewness_sample}\")\n",
    "\n",
    "# Method 6: Sample skewness with biased correction\n",
    "std = np.std(data, ddof=1)  # sample std\n",
    "m3 = np.sum((data - mean) ** 3) / n\n",
    "skewness_biased = m3 / (std ** 3)\n",
    "print(f\"Manual skewness sample (biased): {skewness_biased}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01717ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SCIPY REFERENCE VALUES\n",
      "============================================================\n",
      "Scipy biased (bias=True):    1.7255998349\n",
      "Scipy unbiased (bias=False): 2.1522011230\n",
      "\n",
      "============================================================\n",
      "MANUAL CALCULATION - BIASED (Population Skewness)\n",
      "============================================================\n",
      "Formula: m3 / (m2^1.5)\n",
      "where m3 and m2 are population moments (divide by n)\n",
      "\n",
      "Mean: 54.375\n",
      "m2 (variance): 702.734375\n",
      "m3 (third moment): 32145.99609375\n",
      "Biased skewness: 1.7255998349\n",
      "\n",
      "============================================================\n",
      "MANUAL CALCULATION - UNBIASED (Sample Skewness)\n",
      "============================================================\n",
      "Formula: [n / ((n-1)(n-2))] √ó Œ£(xi - mean)¬≥ / [Œ£(xi - mean)¬≤]^1.5\n",
      "\n",
      "n: 8\n",
      "Correction factor [n/((n-1)(n-2))]: 0.1904761905\n",
      "Sum of cubed deviations: 257167.96875\n",
      "Sum of squared deviations: 5621.875\n",
      "Unbiased skewness: 0.1162079376\n",
      "\n",
      "============================================================\n",
      "VERIFICATION\n",
      "============================================================\n",
      "Biased matches scipy?   True\n",
      "Unbiased matches scipy? False\n",
      "\n",
      "============================================================\n",
      "KEY INSIGHTS\n",
      "============================================================\n",
      "‚Ä¢ Biased value:   1.7256\n",
      "‚Ä¢ Unbiased value: 0.1162\n",
      "‚Ä¢ Difference:     -1.6094\n",
      "‚Ä¢ The unbiased estimator is -93.3% larger\n",
      "‚Ä¢ Both indicate strong positive skew (outlier at 120)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "data = np.array([30, 35, 40, 45, 50, 55, 60, 120])\n",
    "n = len(data)\n",
    "mean = np.mean(data)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SCIPY REFERENCE VALUES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Scipy biased (bias=True):    {stats.skew(data, bias=True):.10f}\")\n",
    "print(f\"Scipy unbiased (bias=False): {stats.skew(data, bias=False):.10f}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MANUAL CALCULATION - BIASED (Population Skewness)\")\n",
    "print(\"=\"*60)\n",
    "print(\"Formula: m3 / (m2^1.5)\")\n",
    "print(\"where m3 and m2 are population moments (divide by n)\")\n",
    "print()\n",
    "\n",
    "# Calculate population moments\n",
    "m2 = np.sum((data - mean) ** 2) / n  # Second moment (variance)\n",
    "m3 = np.sum((data - mean) ** 3) / n  # Third moment\n",
    "\n",
    "# Calculate biased skewness\n",
    "skewness_biased = m3 / (m2 ** 1.5)\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"m2 (variance): {m2}\")\n",
    "print(f\"m3 (third moment): {m3}\")\n",
    "print(f\"Biased skewness: {skewness_biased:.10f}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MANUAL CALCULATION - UNBIASED (Sample Skewness)\")\n",
    "print(\"=\"*60)\n",
    "print(\"Formula: [n / ((n-1)(n-2))] √ó Œ£(xi - mean)¬≥ / [Œ£(xi - mean)¬≤]^1.5\")\n",
    "print()\n",
    "\n",
    "# Calculate components\n",
    "sum_cubed_deviations = np.sum((data - mean) ** 3)\n",
    "sum_squared_deviations = np.sum((data - mean) ** 2)\n",
    "correction_factor = n / ((n - 1) * (n - 2))\n",
    "\n",
    "# Calculate unbiased skewness - CORRECTED\n",
    "# The denominator should be the sum of squared deviations raised to 1.5\n",
    "skewness_unbiased = (correction_factor * sum_cubed_deviations) / (sum_squared_deviations ** 1.5)\n",
    "\n",
    "print(f\"n: {n}\")\n",
    "print(f\"Correction factor [n/((n-1)(n-2))]: {correction_factor:.10f}\")\n",
    "print(f\"Sum of cubed deviations: {sum_cubed_deviations}\")\n",
    "print(f\"Sum of squared deviations: {sum_squared_deviations}\")\n",
    "print(f\"Unbiased skewness: {skewness_unbiased:.10f}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Biased matches scipy?   {np.isclose(skewness_biased, stats.skew(data, bias=True))}\")\n",
    "print(f\"Unbiased matches scipy? {np.isclose(skewness_unbiased, stats.skew(data, bias=False))}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚Ä¢ Biased value:   {skewness_biased:.4f}\")\n",
    "print(f\"‚Ä¢ Unbiased value: {skewness_unbiased:.4f}\")\n",
    "print(f\"‚Ä¢ Difference:     {skewness_unbiased - skewness_biased:.4f}\")\n",
    "print(f\"‚Ä¢ The unbiased estimator is {(skewness_unbiased/skewness_biased - 1)*100:.1f}% larger\")\n",
    "print(f\"‚Ä¢ Both indicate strong positive skew (outlier at 120)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7428943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SCIPY REFERENCE VALUES\n",
      "============================================================\n",
      "Scipy biased (bias=True):    1.7255998349\n",
      "Scipy unbiased (bias=False): 2.1522011230\n",
      "\n",
      "============================================================\n",
      "MANUAL CALCULATION - BIASED (Population Skewness)\n",
      "============================================================\n",
      "Formula: m3 / (m2^1.5)\n",
      "where m3 and m2 are population moments (divide by n)\n",
      "\n",
      "Mean: 54.375\n",
      "m2 (variance): 702.734375\n",
      "m3 (third moment): 32145.99609375\n",
      "Biased skewness: 1.7255998349\n",
      "\n",
      "============================================================\n",
      "MANUAL CALCULATION - UNBIASED (Sample Skewness)\n",
      "============================================================\n",
      "Formula: sqrt(n(n-1))/(n-2) √ó [Œ£(xi - mean)¬≥/n] / [(Œ£(xi - mean)¬≤/n)^1.5]\n",
      "\n",
      "n: 8\n",
      "Adjustment factor [sqrt(n(n-1))/(n-2)]: 1.2472191289\n",
      "m3 (third sample moment): 32145.99609375\n",
      "m2 (second sample moment): 702.734375\n",
      "m3/m2^1.5: 1.7255998349\n",
      "Unbiased skewness: 2.1522011230\n",
      "\n",
      "============================================================\n",
      "VERIFICATION\n",
      "============================================================\n",
      "Biased matches scipy?   True\n",
      "Unbiased matches scipy? True\n",
      "\n",
      "============================================================\n",
      "KEY INSIGHTS\n",
      "============================================================\n",
      "‚Ä¢ Biased value:   1.7256\n",
      "‚Ä¢ Unbiased value: 2.1522\n",
      "‚Ä¢ Difference:     0.4266\n",
      "‚Ä¢ The unbiased estimator is 24.7% larger\n",
      "‚Ä¢ Both indicate strong positive skew (outlier at 120)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "data = np.array([30, 35, 40, 45, 50, 55, 60, 120])\n",
    "n = len(data)\n",
    "mean = np.mean(data)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SCIPY REFERENCE VALUES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Scipy biased (bias=True):    {stats.skew(data, bias=True):.10f}\")\n",
    "print(f\"Scipy unbiased (bias=False): {stats.skew(data, bias=False):.10f}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MANUAL CALCULATION - BIASED (Population Skewness)\")\n",
    "print(\"=\"*60)\n",
    "print(\"Formula: m3 / (m2^1.5)\")\n",
    "print(\"where m3 and m2 are population moments (divide by n)\")\n",
    "print()\n",
    "\n",
    "# Calculate population moments\n",
    "m2 = np.sum((data - mean) ** 2) / n  # Second moment (variance)\n",
    "m3 = np.sum((data - mean) ** 3) / n  # Third moment\n",
    "\n",
    "# Calculate biased skewness\n",
    "skewness_biased = m3 / (m2 ** 1.5)\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"m2 (variance): {m2}\")\n",
    "print(f\"m3 (third moment): {m3}\")\n",
    "print(f\"Biased skewness: {skewness_biased:.10f}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MANUAL CALCULATION - UNBIASED (Sample Skewness)\")\n",
    "print(\"=\"*60)\n",
    "print(\"Formula: sqrt(n(n-1))/(n-2) √ó [Œ£(xi - mean)¬≥/n] / [(Œ£(xi - mean)¬≤/n)^1.5]\")\n",
    "print()\n",
    "\n",
    "# Calculate components\n",
    "sum_cubed_deviations = np.sum((data - mean) ** 3)\n",
    "sum_squared_deviations = np.sum((data - mean) ** 2)\n",
    "\n",
    "# Correct formula for unbiased skewness (Fisher-Pearson)\n",
    "# G1 = [sqrt(n(n-1)) / (n-2)] * [m3 / m2^1.5]\n",
    "# where m3 and m2 are sample moments\n",
    "m3_sample = sum_cubed_deviations / n\n",
    "m2_sample = sum_squared_deviations / n\n",
    "adjustment_factor = np.sqrt(n * (n - 1)) / (n - 2)\n",
    "\n",
    "skewness_unbiased = adjustment_factor * (m3_sample / (m2_sample ** 1.5))\n",
    "\n",
    "print(f\"n: {n}\")\n",
    "print(f\"Adjustment factor [sqrt(n(n-1))/(n-2)]: {adjustment_factor:.10f}\")\n",
    "print(f\"m3 (third sample moment): {m3_sample}\")\n",
    "print(f\"m2 (second sample moment): {m2_sample}\")\n",
    "print(f\"m3/m2^1.5: {m3_sample / (m2_sample ** 1.5):.10f}\")\n",
    "print(f\"Unbiased skewness: {skewness_unbiased:.10f}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Biased matches scipy?   {np.isclose(skewness_biased, stats.skew(data, bias=True))}\")\n",
    "print(f\"Unbiased matches scipy? {np.isclose(skewness_unbiased, stats.skew(data, bias=False))}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚Ä¢ Biased value:   {skewness_biased:.4f}\")\n",
    "print(f\"‚Ä¢ Unbiased value: {skewness_unbiased:.4f}\")\n",
    "print(f\"‚Ä¢ Difference:     {skewness_unbiased - skewness_biased:.4f}\")\n",
    "print(f\"‚Ä¢ The unbiased estimator is {(skewness_unbiased/skewness_biased - 1)*100:.1f}% larger\")\n",
    "print(f\"‚Ä¢ Both indicate strong positive skew (outlier at 120)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28c231d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.152201122975111\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "data = [30,35,40,45,50,55,60,120]\n",
    "skewness = stats.skew(data, bias=False) # sample skewness\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a1c0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1522011229751112\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.Series([30,35,40,45,50,55,60,120])\n",
    "skewness = df.skew()  # sample skewness\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5558b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scipy: 2.152201122975111\n",
      "Pandas: 2.1522011229751112\n",
      "Are they equal? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "data = [30, 35, 40, 45, 50, 55, 60, 120]\n",
    "\n",
    "# Scipy skewness\n",
    "skew_scipy = stats.skew(data, bias=False)  \n",
    "print(f\"Scipy: {skew_scipy}\")\n",
    "\n",
    "# Pandas skewness\n",
    "skew_pandas = pd.Series(data).skew()\n",
    "print(f\"Pandas: {skew_pandas}\")\n",
    "\n",
    "# They're actually the same!\n",
    "print(f\"Are they equal? {np.isclose(float(skew_scipy), float(skew_pandas))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd24435",
   "metadata": {},
   "source": [
    "üîπ What is Kurtosis?\n",
    "\n",
    "Kurtosis measures how peaked or flat a distribution is compared to the normal distribution.\n",
    "It‚Äôs not about skew (left vs right), but about the tails and peak.\n",
    "\n",
    "Think of it like comparing mountains:\n",
    "\n",
    "Some are tall & sharp ‚Üí lots of data packed near the center but also heavy tails (extremes).\n",
    "\n",
    "Some are flat & wide ‚Üí more spread in the middle, fewer extremes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcea0b1",
   "metadata": {},
   "source": [
    "üîπ Types of Kurtosis\n",
    "\n",
    "Mesokurtic ‚Üí normal-like (baseline).\n",
    "\n",
    "Bell-shaped, moderate tails.\n",
    "\n",
    "Example: height distribution.\n",
    "\n",
    "Leptokurtic ‚Üí ‚Äúpeaked‚Äù with heavy tails.\n",
    "\n",
    "More extreme outliers.\n",
    "\n",
    "Example: financial returns (many values near mean, but occasional huge swings).\n",
    "\n",
    "Platykurtic ‚Üí ‚Äúflat‚Äù with light tails.\n",
    "\n",
    "Fewer outliers, data more evenly spread.\n",
    "\n",
    "Example: uniform-like distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64873de6",
   "metadata": {},
   "source": [
    "üîπ Formula (classical definition)\n",
    "\n",
    "$$g2 = \\frac{\\frac{1}{n} \\sum(x_i - \\bar{x})^4}{s^4}$$\n",
    "\n",
    "\n",
    "Numerator: 4th power of deviations (sensitive to extremes).\n",
    "\n",
    "Denominator: standard deviation to the 4th.\n",
    "\n",
    "By convention, excess kurtosis $= g_2 - 3$ (so normal distribution = 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ee115e",
   "metadata": {},
   "source": [
    "üîπ Why It Matters\n",
    "\n",
    "High kurtosis = prone to outliers (risky if you assume normality).\n",
    "\n",
    "Low kurtosis = fewer outliers, flatter distribution.\n",
    "\n",
    "Tells us about data reliability: in finance or ML, high kurtosis warns you that rare but extreme values could dominate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f22ec",
   "metadata": {},
   "source": [
    "That‚Äôs a sharp observation üëç ‚Äî let‚Äôs refine it a bit so you get the mental picture right:\n",
    "\n",
    "Leptokurtic\n",
    "\n",
    "Center peak: taller and sharper (thinner in the middle).\n",
    "\n",
    "Tails: heavier/longer than normal ‚Üí more outliers.\n",
    "\n",
    "Think: a mountain spike with deep valleys ‚Üí most data near the mean, but a few way out.\n",
    "\n",
    "Platykurtic\n",
    "\n",
    "Center peak: flatter, plateau-like.\n",
    "\n",
    "Tails: lighter/shorter than normal ‚Üí fewer outliers.\n",
    "\n",
    "Think: a mesa (flat top hill) ‚Üí data more evenly spread out, no big extremes.\n",
    "\n",
    "Mesokurtic (normal)\n",
    "\n",
    "In-between ‚Üí bell curve.\n",
    "\n",
    "So your phrasing is partly correct:\n",
    "\n",
    "Yes, leptokurtic has a taller peak and longer/heavier tails.\n",
    "\n",
    "Platykurtic is indeed flatter (plateau), but its tails are shorter/lighter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24f10f4",
   "metadata": {},
   "source": [
    "üîπ What ‚Äúheavier tails‚Äù means\n",
    "\n",
    "When statisticians say a distribution has heavier tails, they don‚Äôt mean there are more data points in the tails. They mean:\n",
    "\n",
    "The probability of extreme values is higher than in a normal distribution.\n",
    "\n",
    "So, if you randomly sample from the distribution, you‚Äôre more likely to occasionally get a very large or very small value.\n",
    "\n",
    "üëâ In other words: outliers are rare, but when they happen, they‚Äôre more extreme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35234acc",
   "metadata": {},
   "source": [
    "üîπ Example analogy\n",
    "\n",
    "Imagine two cities:\n",
    "\n",
    "City A (Normal kurtosis): most people are average height, some are tall/short, but very few are very tall or very short.\n",
    "\n",
    "City B (Leptokurtic): also has mostly average heights, but once in a while, you meet someone extremely tall or extremely short.\n",
    "\n",
    "So the tails are ‚Äúheavier‚Äù in the sense that the rare values are further out compared to normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffabb2e",
   "metadata": {},
   "source": [
    "üîπ Platykurtic comparison\n",
    "\n",
    "Platykurtic = flatter top, lighter tails.\n",
    "\n",
    "People‚Äôs heights are more spread around the average, but extreme outliers are less likely.\n",
    "\n",
    "You almost never meet the ‚Äúgiants‚Äù or ‚Äútiny‚Äù people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296d962d",
   "metadata": {},
   "source": [
    "üîπ Recap: Kurtosis Types\n",
    "\n",
    "Mesokurtic (normal-like)\n",
    "\n",
    "Bell-shaped, tails like the normal distribution.\n",
    "\n",
    "Example: standardized test scores.\n",
    "\n",
    "Leptokurtic (high kurtosis, >0 excess)\n",
    "\n",
    "Tall/narrow peak + heavy tails.\n",
    "\n",
    "Most values cluster tightly near the mean, but outliers (when they appear) are very extreme.\n",
    "\n",
    "Example: financial returns (mostly small day-to-day moves, but sometimes huge crashes or spikes).\n",
    "\n",
    "Platykurtic (low kurtosis, <0 excess)\n",
    "\n",
    "Flat, plateau-like peak + light tails.\n",
    "\n",
    "Data spread more evenly, fewer extreme outliers.\n",
    "\n",
    "Example: uniform-like distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b567a08e",
   "metadata": {},
   "source": [
    "üîπ Why It Matters\n",
    "\n",
    "High kurtosis: means outlier-prone ‚Üí need robust statistics (median, IQR, robust regression).\n",
    "\n",
    "Low kurtosis: fewer surprises, data is more ‚Äústable.‚Äù\n",
    "\n",
    "In ML/EDA: kurtosis is a quick way to check tail risk (good for finance, quality control, anomaly detection)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f437e3d",
   "metadata": {},
   "source": [
    "So the mapping goes like this:\n",
    "\n",
    "Leptokurtic: tall peak, fat tails ‚Üí more prone to big outliers.\n",
    "\n",
    "Platykurtic: flat peak, thin tails ‚Üí fewer outliers.\n",
    "\n",
    "Mesokurtic: normal curve in between."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81c04b",
   "metadata": {},
   "source": [
    "üîπ Formula for Sample Kurtosis\n",
    "\n",
    "for a dataset $x_1, x_2, ..., x_n$\n",
    "\n",
    "\n",
    "$$g_2 = \\frac{\\frac{1}{n} \\sum^n_{i=1}(x_i - \\bar{x})^4}{(\\frac{1}{n} \\sum^n_{i=1}(x_i - \\bar{x})^2)^2} - 3$$\n",
    "\n",
    "Numerator = 4th central moment (measures ‚Äúpeakedness‚Äù)\n",
    "\n",
    "Denominator = squared variance (normalizes scale)\n",
    "\n",
    "Subtract 3 ‚Üí so that normal distribution = 0 (this is called excess kurtosis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e2dce7",
   "metadata": {},
   "source": [
    "üîπ Interpretation\n",
    "\n",
    "$g_2 > 0 :$ Leptokurtic (sharper peak, heavier tails).\n",
    "\n",
    "$g_2 < 0 :$ Platykurtic (flatter peak, lighter tails).\n",
    "\n",
    "$g_2 = 0 :$ Mesokurtic (normal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f81f0c",
   "metadata": {},
   "source": [
    "Summary of results for [2,3,3,4,4,4,5,5,6]:\n",
    "\n",
    "n = 9\n",
    "\n",
    "Mean = 4.0\n",
    "\n",
    "Population variance = 1.333333\n",
    "\n",
    "Population SD = 1.154701\n",
    "\n",
    "4th central moment = 4.0\n",
    "\n",
    "Raw kurtosis (no subtraction) = 2.25\n",
    "\n",
    "Excess kurtosis =2.25‚àí3=‚àí0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9808139",
   "metadata": {},
   "source": [
    "Excess kurtosis = ‚Äì0.75\n",
    "\n",
    "That‚Äôs below 0, which means the distribution is platykurtic ‚Üí flatter peak and lighter tails than normal.\n",
    "\n",
    "So the interpretation is:\n",
    "\n",
    "The data are fairly symmetric (mean = 4, it‚Äôs balanced around the middle).\n",
    "\n",
    "But the shape is flatter than a normal bell curve, with fewer extreme values ‚Üí platykurtic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a870b718",
   "metadata": {},
   "source": [
    "üí° Memory aid:\n",
    "\n",
    "Skewness ‚Üí left vs right tilt.\n",
    "\n",
    "Kurtosis ‚Üí sharp vs flat peak (outlier-proneness)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d3fcde",
   "metadata": {},
   "source": [
    "üîπ Shape Summary\n",
    "\n",
    "Symmetry vs Skewness\n",
    "\n",
    "Symmetric ‚Üí mean ‚âà median.\n",
    "\n",
    "Right-skew ‚Üí tail stretches right, mean > median.\n",
    "\n",
    "Left-skew ‚Üí tail stretches left, mean < median.\n",
    "\n",
    "Kurtosis\n",
    "\n",
    "Mesokurtic (‚âà0) ‚Üí normal-like.\n",
    "\n",
    "Leptokurtic (>0) ‚Üí sharp peak, heavy tails ‚Üí more extreme outliers.\n",
    "\n",
    "Platykurtic (<0) ‚Üí flatter, light tails ‚Üí fewer outliers.\n",
    "\n",
    "Why Shape Matters\n",
    "\n",
    "Shape tells you which summary stats are reliable.\n",
    "\n",
    "Normal-like ‚Üí use mean & SD.\n",
    "\n",
    "Skewed or outlier-prone ‚Üí use median & IQR.\n",
    "\n",
    "Heavy tails ‚Üí be cautious, extremes can dominate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe96157",
   "metadata": {},
   "source": [
    "So now you‚Äôve covered the three pillars of describing data:\n",
    "\n",
    "Center (mean, median)\n",
    "\n",
    "Spread (SD, IQR)\n",
    "\n",
    "Shape (skewness, kurtosis)\n",
    "\n",
    "Together, these give a complete statistical picture of a dataset before moving on to inferential or modeling work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca7ab9",
   "metadata": {},
   "source": [
    "üîπ Natural next topics\n",
    "\n",
    "Probability distributions\n",
    "\n",
    "Why we model data with distributions (normal, uniform, binomial, etc.).\n",
    "\n",
    "Normal distribution as the ‚Äúbenchmark‚Äù (ties back to mean/SD/skew/kurtosis).\n",
    "\n",
    "The Normal Distribution in depth\n",
    "\n",
    "Properties, z-scores (you‚Äôve touched on these), standardization.\n",
    "\n",
    "Empirical rule (68‚Äì95‚Äì99.7).\n",
    "\n",
    "Why so many real-world things are approximately normal.\n",
    "\n",
    "Sampling distributions & Central Limit Theorem (CLT)\n",
    "\n",
    "Bridge from descriptive stats ‚Üí inferential stats.\n",
    "\n",
    "Key idea: sample means follow a normal distribution even if the data aren‚Äôt perfectly normal.\n",
    "\n",
    "Inferential statistics\n",
    "\n",
    "Confidence intervals.\n",
    "\n",
    "Hypothesis testing (p-values, t-tests, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec999e34",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
